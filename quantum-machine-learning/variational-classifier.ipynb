{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fitting the parity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(layer_weights):\n",
    "    for wire in range(4):\n",
    "        qml.Rot(*layer_weights[wire], wires=wire)\n",
    "\n",
    "    for wires in ([0, 1], [1, 2], [2, 3], [3, 0]):\n",
    "        qml.CNOT(wires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_preparation(x):\n",
    "    qml.BasisState(x, wires=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    state_preparation(x)\n",
    "\n",
    "    for layer_weights in weights:\n",
    "        layer(layer_weights)\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost: standard square loss that measures the distance between target labels and model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    return np.mean((labels- - qml.math.stack(predictions))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy: the proportion of predictions that agree with a set of target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
    "    acc = acc / len(labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The features and labels considered in the interation of the optimization routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [0 0 0 1], y = 1\n",
      "x = [0 0 1 0], y = 1\n",
      "x = [0 1 0 0], y = 1\n",
      "x = [0 1 0 1], y = -1\n",
      "x = [0 1 1 0], y = -1\n",
      "x = [0 1 1 1], y = 1\n",
      "x = [1 0 0 0], y = 1\n",
      "x = [1 0 0 1], y = -1\n",
      "x = [1 0 1 1], y = 1\n",
      "x = [1 1 1 1], y = -1\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"variational_classifier/data/parity_train.txt\", dtype=int)\n",
    "X = np.array(data[:, :-1])\n",
    "Y = np.array(data[:, -1])\n",
    "Y = Y * 2 - 1  # shift label from {0, 1} to {-1, 1}\n",
    "\n",
    "for x,y in zip(X, Y):\n",
    "    print(f\"x = {x}, y = {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[[ 0.01764052  0.00400157  0.00978738]\n",
      "  [ 0.02240893  0.01867558 -0.00977278]\n",
      "  [ 0.00950088 -0.00151357 -0.00103219]\n",
      "  [ 0.00410599  0.00144044  0.01454274]]\n",
      "\n",
      " [[ 0.00761038  0.00121675  0.00443863]\n",
      "  [ 0.00333674  0.01494079 -0.00205158]\n",
      "  [ 0.00313068 -0.00854096 -0.0255299 ]\n",
      "  [ 0.00653619  0.00864436 -0.00742165]]]\n",
      "Bias:  0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "num_qubits = 4\n",
    "num_layers = 2\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(\"Weights:\", weights_init)\n",
    "print(\"Bias: \", bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = NesterovMomentumOptimizer(0.5)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:    1 | Cost: 2.3182893 | Accuracy: 0.5000000\n",
      "Iter:    2 | Cost: 2.3025760 | Accuracy: 0.5000000\n",
      "Iter:    3 | Cost: 1.7299004 | Accuracy: 0.5000000\n",
      "Iter:    4 | Cost: 1.5468497 | Accuracy: 0.6000000\n",
      "Iter:    5 | Cost: 0.9463478 | Accuracy: 0.4000000\n",
      "Iter:    6 | Cost: 1.0839446 | Accuracy: 0.8000000\n",
      "Iter:    7 | Cost: 1.7603336 | Accuracy: 0.6000000\n",
      "Iter:    8 | Cost: 1.1216115 | Accuracy: 0.7000000\n",
      "Iter:    9 | Cost: 1.1916607 | Accuracy: 0.4000000\n",
      "Iter:   10 | Cost: 1.1520790 | Accuracy: 0.4000000\n",
      "Iter:   11 | Cost: 1.7552595 | Accuracy: 0.4000000\n",
      "Iter:   12 | Cost: 1.0007639 | Accuracy: 0.2000000\n",
      "Iter:   13 | Cost: 1.3951375 | Accuracy: 0.4000000\n",
      "Iter:   14 | Cost: 1.6916232 | Accuracy: 0.6000000\n",
      "Iter:   15 | Cost: 1.0047522 | Accuracy: 0.4000000\n",
      "Iter:   16 | Cost: 0.8404211 | Accuracy: 0.4000000\n",
      "Iter:   17 | Cost: 1.8333014 | Accuracy: 0.4000000\n",
      "Iter:   18 | Cost: 1.1545727 | Accuracy: 0.5000000\n",
      "Iter:   19 | Cost: 1.1489902 | Accuracy: 0.4000000\n",
      "Iter:   20 | Cost: 1.4333985 | Accuracy: 0.4000000\n",
      "Iter:   21 | Cost: 1.6113459 | Accuracy: 0.6000000\n",
      "Iter:   22 | Cost: 1.2656325 | Accuracy: 0.4000000\n",
      "Iter:   23 | Cost: 0.9598299 | Accuracy: 0.5000000\n",
      "Iter:   24 | Cost: 1.2836734 | Accuracy: 0.4000000\n",
      "Iter:   25 | Cost: 1.0799080 | Accuracy: 0.6000000\n",
      "Iter:   26 | Cost: 0.9892816 | Accuracy: 0.4000000\n",
      "Iter:   27 | Cost: 1.0164465 | Accuracy: 0.4000000\n",
      "Iter:   28 | Cost: 0.7615266 | Accuracy: 0.1000000\n",
      "Iter:   29 | Cost: 0.9135662 | Accuracy: 0.2000000\n",
      "Iter:   30 | Cost: 1.0412708 | Accuracy: 0.4000000\n",
      "Iter:   31 | Cost: 1.1208766 | Accuracy: 0.6000000\n",
      "Iter:   32 | Cost: 0.9941304 | Accuracy: 0.5000000\n",
      "Iter:   33 | Cost: 1.7344299 | Accuracy: 0.6000000\n",
      "Iter:   34 | Cost: 0.7930840 | Accuracy: 0.1000000\n",
      "Iter:   35 | Cost: 0.8479265 | Accuracy: 0.3000000\n",
      "Iter:   36 | Cost: 1.3651102 | Accuracy: 0.4000000\n",
      "Iter:   37 | Cost: 1.1560915 | Accuracy: 0.4000000\n",
      "Iter:   38 | Cost: 1.4970466 | Accuracy: 0.4000000\n",
      "Iter:   39 | Cost: 0.9062331 | Accuracy: 0.5000000\n",
      "Iter:   40 | Cost: 1.5228374 | Accuracy: 0.4000000\n",
      "Iter:   41 | Cost: 1.4426049 | Accuracy: 0.4000000\n",
      "Iter:   42 | Cost: 1.1123223 | Accuracy: 0.4000000\n",
      "Iter:   43 | Cost: 0.8018243 | Accuracy: 0.3000000\n",
      "Iter:   44 | Cost: 1.0111092 | Accuracy: 0.5000000\n",
      "Iter:   45 | Cost: 1.3033194 | Accuracy: 0.6000000\n",
      "Iter:   46 | Cost: 1.0185267 | Accuracy: 0.5000000\n",
      "Iter:   47 | Cost: 1.1854291 | Accuracy: 0.4000000\n",
      "Iter:   48 | Cost: 1.0724646 | Accuracy: 0.6000000\n",
      "Iter:   49 | Cost: 1.0220803 | Accuracy: 0.4000000\n",
      "Iter:   50 | Cost: 1.0561074 | Accuracy: 0.6000000\n",
      "Iter:   51 | Cost: 0.9418515 | Accuracy: 0.4000000\n",
      "Iter:   52 | Cost: 1.0200357 | Accuracy: 0.6000000\n",
      "Iter:   53 | Cost: 0.8044767 | Accuracy: 0.4000000\n",
      "Iter:   54 | Cost: 0.9165470 | Accuracy: 0.6000000\n",
      "Iter:   55 | Cost: 0.9052112 | Accuracy: 0.5000000\n",
      "Iter:   56 | Cost: 0.6898065 | Accuracy: 0.2000000\n",
      "Iter:   57 | Cost: 0.6888938 | Accuracy: 0.4000000\n",
      "Iter:   58 | Cost: 0.5447909 | Accuracy: 0.0000000\n",
      "Iter:   59 | Cost: 0.4197732 | Accuracy: 0.0000000\n",
      "Iter:   60 | Cost: 0.2604239 | Accuracy: 0.0000000\n",
      "Iter:   61 | Cost: 0.0331922 | Accuracy: 0.0000000\n",
      "Iter:   62 | Cost: 0.0188208 | Accuracy: 0.0000000\n",
      "Iter:   63 | Cost: 0.0394577 | Accuracy: 0.0000000\n",
      "Iter:   64 | Cost: 0.0246899 | Accuracy: 0.0000000\n",
      "Iter:   65 | Cost: 0.0215364 | Accuracy: 0.0000000\n",
      "Iter:   66 | Cost: 0.0149602 | Accuracy: 0.0000000\n",
      "Iter:   67 | Cost: 0.0146160 | Accuracy: 0.0000000\n",
      "Iter:   68 | Cost: 0.0069703 | Accuracy: 0.0000000\n",
      "Iter:   69 | Cost: 0.0039785 | Accuracy: 0.0000000\n",
      "Iter:   70 | Cost: 0.0026799 | Accuracy: 0.0000000\n",
      "Iter:   71 | Cost: 0.0014895 | Accuracy: 0.0000000\n",
      "Iter:   72 | Cost: 0.0016244 | Accuracy: 0.0000000\n",
      "Iter:   73 | Cost: 0.0013332 | Accuracy: 0.0000000\n",
      "Iter:   74 | Cost: 0.0018617 | Accuracy: 0.0000000\n",
      "Iter:   75 | Cost: 0.0019762 | Accuracy: 0.0000000\n",
      "Iter:   76 | Cost: 0.0014445 | Accuracy: 0.0000000\n",
      "Iter:   77 | Cost: 0.0012162 | Accuracy: 0.0000000\n",
      "Iter:   78 | Cost: 0.0012590 | Accuracy: 0.0000000\n",
      "Iter:   79 | Cost: 0.0013382 | Accuracy: 0.0000000\n",
      "Iter:   80 | Cost: 0.0007269 | Accuracy: 0.0000000\n",
      "Iter:   81 | Cost: 0.0005314 | Accuracy: 0.0000000\n",
      "Iter:   82 | Cost: 0.0004185 | Accuracy: 0.0000000\n",
      "Iter:   83 | Cost: 0.0003423 | Accuracy: 0.0000000\n",
      "Iter:   84 | Cost: 0.0002926 | Accuracy: 0.0000000\n",
      "Iter:   85 | Cost: 0.0002614 | Accuracy: 0.0000000\n",
      "Iter:   86 | Cost: 0.0002193 | Accuracy: 0.0000000\n",
      "Iter:   87 | Cost: 0.0004562 | Accuracy: 0.0000000\n",
      "Iter:   88 | Cost: 0.0001454 | Accuracy: 0.0000000\n",
      "Iter:   89 | Cost: 0.0001246 | Accuracy: 0.0000000\n",
      "Iter:   90 | Cost: 0.0001191 | Accuracy: 0.0000000\n",
      "Iter:   91 | Cost: 0.0000991 | Accuracy: 0.0000000\n",
      "Iter:   92 | Cost: 0.0000891 | Accuracy: 0.0000000\n",
      "Iter:   93 | Cost: 0.0000893 | Accuracy: 0.0000000\n",
      "Iter:   94 | Cost: 0.0000817 | Accuracy: 0.0000000\n",
      "Iter:   95 | Cost: 0.0000833 | Accuracy: 0.0000000\n",
      "Iter:   96 | Cost: 0.0001267 | Accuracy: 0.0000000\n",
      "Iter:   97 | Cost: 0.0000621 | Accuracy: 0.0000000\n",
      "Iter:   98 | Cost: 0.0000572 | Accuracy: 0.0000000\n",
      "Iter:   99 | Cost: 0.0000842 | Accuracy: 0.0000000\n",
      "Iter:  100 | Cost: 0.0000478 | Accuracy: 0.0000000\n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(100):\n",
    "\n",
    "    # Update the weights by one optimizer step, using only a limited batch of data\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias = opt.step(cost, weights, bias, X=X_batch, Y=Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "\n",
    "    current_cost = cost(weights, bias, X, Y)\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(f\"Iter: {it+1:4d} | Cost: {current_cost:0.7f} | Accuracy: {acc:0.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [0 0 0 0], y = -1, pred=1.0\n",
      "x = [0 0 1 1], y = -1, pred=1.0\n",
      "x = [1 0 1 0], y = -1, pred=1.0\n",
      "x = [1 1 1 0], y = 1, pred=-1.0\n",
      "x = [1 1 0 0], y = -1, pred=1.0\n",
      "x = [1 1 0 1], y = 1, pred=-1.0\n",
      "Accuracy on unseen data: 0.0\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"variational_classifier/data/parity_test.txt\", dtype=int)\n",
    "X_test = np.array(data[:, :-1])\n",
    "Y_test = np.array(data[:, -1])\n",
    "Y_test = Y_test * 2 - 1  # shift label from {0, 1} to {-1, 1}\n",
    "\n",
    "predictions_test = [np.sign(variational_classifier(weights, bias, x)) for x in X_test]\n",
    "\n",
    "for x,y,p in zip(X_test, Y_test, predictions_test):\n",
    "    print(f\"x = {x}, y = {y}, pred={p}\")\n",
    "\n",
    "acc_test = accuracy(Y_test, predictions_test)\n",
    "print(\"Accuracy on unseen data:\", acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
